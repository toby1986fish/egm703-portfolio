{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "residential-harrison",
   "metadata": {},
   "source": [
    "# EGM703 - Week 2 Practical: Hyperspectral image analysis\n",
    "\n",
    "## Overview\n",
    "In the lectures and reading this week, you've learned about hyperspectral remote sensing and a number of different methods for analyzing hyperspectral data. In this practical, we'll gain some experience working with hyperspectral data, using a few examples written in python.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "- Open and view data using xarray\n",
    "- Perform atmospheric correction using dark object subtraction\n",
    "- Use spectral angle matching to compare spectral signatures and identify surfaces\n",
    "- Gain some familiarity with Spectral Python (SPy), a python package for analyzing hyperspectral images.\n",
    "\n",
    "## Data provided\n",
    "In the `data` folder, you should have the following files:\n",
    "\n",
    "- combine_spectral_library.py - a python script that can be used to add additional spectra to **spectral_library.csv**\n",
    "- EO1H0380352003173110PF_MTL_L1T.TXT - the L1T (\"level-1 terrain corrected\") metadata file for the EO-1 image\n",
    "- solar_spectra.csv - a csv file containing values of extraterrestrial (top of atmosphere) radiance as a function of wavelength\n",
    "- spectral_library.csv - a csv file containing example reflectance spectra for different surface types\n",
    "\n",
    "You'll need to download the hyperspectral data from Blackboard, or from the Google Drive link [here](https://drive.google.com/file/d/18EHJpSbkbARJ2Rt6NndBSPe9SlcYr_iO/view?usp=sharing) - be sure to save it to the `data` folder.\n",
    "\n",
    "The datast provided is an EO-1 Hyperion image, acquired 22 June 2003, over an area near the border of Arizona and Nevada in the southwestern United States. To prepare the dataset, I have converted the original L1T DN values to spectral radiance, then combined and re-ordered the bands (by wavelength) into a single netcdf file.\n",
    "\n",
    "## 1 Getting started\n",
    "As always, we need to run the following cell to import the necessary libraries, as well as define a couple of functions that we'll use for displaying the image(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bulgarian-milwaukee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cartopy.crs as ccrs\n",
    "from scipy.interpolate import interp1d\n",
    "import spectral as spy\n",
    "\n",
    "\n",
    "def plot_rgb(ax, ds, bands, crs, variable='radiance'):\n",
    "    \"\"\"\n",
    "    Plot an RGB composite of an image using the provided bands.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ax - a matplotlib Axes object\n",
    "    ds - the xarray DataSet with a 'radiance' variable representing the image\n",
    "    bands - a list of the three bands to display, in R, G, B order\n",
    "    crs - a CRS object to pass to ax.imshow()\n",
    "    variable - which variable from ds to show (default: radiance)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    ax - the matplotlib Axes object\n",
    "    \"\"\"\n",
    "    dispimg = []\n",
    "    for b in bands:\n",
    "        this_band = ds[variable].loc[b].values\n",
    "        this_band = percentile_stretch(this_band)\n",
    "        dispimg.append(this_band)\n",
    "    dispimg = np.array(dispimg)\n",
    "    ax.imshow(dispimg.transpose([1, 2, 0]), transform=crs, extent=[ds.x.min(), ds.x.max(), ds.y.min(), ds.y.max()])\n",
    "    return ax\n",
    "    \n",
    "\n",
    "def percentile_stretch(image, pmin=0., pmax=100.):\n",
    "    \"\"\"\n",
    "    Apply a linear percentile stretch to an image.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image - the input image\n",
    "    pmin - the minimum percentile to use in the stretch\n",
    "    pmax - the maximum percentile to use in the stretch\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    stretched - the stretched image band\n",
    "    \"\"\"\n",
    "    # here, we make sure that pmin < pmax, and that they are between 0, 100\n",
    "    if not 0 <= pmin < pmax <= 100:\n",
    "        raise ValueError('0 <= pmin < pmax <= 100')\n",
    "    # here, we make sure that the image is only 2-dimensional\n",
    "    if not image.ndim == 2:\n",
    "        raise ValueError('Image can only have two dimensions (row, column)')\n",
    "    \n",
    "    minval = np.percentile(image[image > 0], pmin)\n",
    "    maxval = np.percentile(image[image > 0], pmax)\n",
    "    \n",
    "    stretched = (image - minval) / (maxval - minval) # stretch the image to 0, 1\n",
    "    stretched[image < minval] = 0 # set anything less than minval to the new minimum, 0.\n",
    "    stretched[image > maxval] = 1 # set anything greater than maxval to the new maximum, 1.\n",
    "    \n",
    "    return stretched"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entire-pencil",
   "metadata": {},
   "source": [
    "### 1.1 Loading the data\n",
    "\n",
    "The image we'll be using in this practical is an EO-1 Hyperion image, acquired 22 June 2003. The images are terrain-corrected and radiometrically calibrated by the USGS. I have combined them into a single NetCDF file, re-scaled the values to radiance, and removed any bands that don't contain data. For more information about Hyperion images, including the different processing levels, see this [USGS link](https://www.usgs.gov/centers/eros/science/usgs-eros-archive-earth-observing-one-eo-1-hyperion).\n",
    "\n",
    "`xarray` doesn't automatically read all of the file from the disk. This means that once the image is opened, we also need to load the data using `Dataset.load()` - this is mostly so that we don't have to read the data from the disk every time we want to plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-amazon",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset('data/EO1H0380352003173110PF.nc')\n",
    "ds.load() # this will load the entire image into memory - it may take a minute!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revolutionary-zoning",
   "metadata": {},
   "source": [
    "If you click on the document logo in each row of the **Coordinates** or the **Data variables**, you can display additional information about each variable, such as the units - this is one of the advantages of the netCDF format, which allows important metadata to be kept in the same file as the data itself.\n",
    "\n",
    "### 1.2 Selecting bands using xarray\n",
    "\n",
    "Once we have the data loaded, we can start to explore. In the output above, you should see the different coordinates - `band`, `x`, and `y`. You should also see the following data variables:\n",
    "\n",
    "- `crs`: this is the CRS variable that tells a GIS software how to display the images\n",
    "- `radiance`: these are the radiance values\n",
    "- `wavelength`: this is the wavelength corresponding to each band.\n",
    "\n",
    "Note, for example, that `radiance` has three dimensions: `band`, `y`, and `x`, while `wavelength` has only one: `band`. This also tells the index order for a given value in the `radiance` array: `ds['radiance'][0, 1000, 500]` corresponds to the first band, the 1001st row, and the 501st column.\n",
    "\n",
    "This can be a little bit confusing here - the first band (index 0) is actually Hyperion Band 8 (because Bands 1-7 have no data). Rather than selecting by the array index, though, we can select by the `coordinate` - in this case, we would use the actual Hyperion band number. The following should give us information about Band 8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fleet-services",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['radiance'].loc[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44e2e27-5ff7-4eba-8e7b-a73c9f5d1abd",
   "metadata": {},
   "source": [
    "This returns the Band 8 radiance as a `DataArray` object - this is an array with 3381 rows and 1121 columns. In addition to the associated coordinates, you can also see that there are a number of attributes for the object: the units are W m<sup>-2</sup> sr<sup>-1</sup> Âµm<sup>-1</sup>, indicating that this is a spectral radiance. The `grid_mapping` attribute is something that tells our GIS software where to look to get the georeferencing information about the image - in this case, it's the `crs` variable.\n",
    "\n",
    "If we want to see what wavelength is associated with band 8, we can again use `.loc`, but this time on the `wavelength` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fd21a7-19d1-4c37-9055-a8b36bca8c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['wavelength'].loc[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extended-impression",
   "metadata": {},
   "source": [
    "Here, you should hopefully see that the central wavelength of band 8 is 426.82 nm, which is in the violet portion of the visible spectrum.\n",
    "\n",
    "### 1.3 Displaying a single band\n",
    "Because the different `radiance` bands are **DataArrays**, we can display them using the `.plot()` method ([documentation](https://docs.xarray.dev/en/latest/generated/xarray.DataArray.plot.html)) method. As we saw in EGM722, if we want to plot things geographically we need to first set up the axis by setting the `projection` with a `cartopy` CRS object - in this case, we'll use WGS84 UTM Zone 12N.\n",
    "\n",
    "We'll again have a look at Band 8 to start with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medieval-bangladesh",
   "metadata": {},
   "outputs": [],
   "source": [
    "utm_crs = ccrs.UTM(12) # set the projection as WGS84 UTM 12N\n",
    "fig, ax = plt.subplots(1, 1, subplot_kw=dict(projection=utm_crs), figsize=(5, 8)) # create an axis with this projection\n",
    "\n",
    "ds['radiance'].loc[8].plot(cmap='gray') # plot band 8 using .plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247d2ffd-cb7e-4cc5-b9f2-3b18b056dec6",
   "metadata": {},
   "source": [
    "You can zoom in the image above to see the different features in the scene - you should see a large lake (Grand Wash) around halfway down the image, along with a large river just South of the lake (the Colorado River). In the Northern part of the image, you should also be able to see a number of canyons and cliffs - the geology in this area, as we'll see later on, is primarily sandstone/sedimentary rocks with some volcanics thrown in for flavor.\n",
    "\n",
    "Note also that `.plot()` adds a title (telling us what band is being plotted), and a colorbar with a label that includes the units (!) We can of course update these labels if we want to. First, we'll look at the output of `fig.get_axes()` ([documentation](https://matplotlib.org/stable/api/_as_gen/matplotlib.figure.Figure.get_axes.html)) to see all of the **Axes** object contained within the figure - you should see two objects in the list below - one **GeoAxes** (where the band is plotted), and one **Axes** (the colorbar):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47a6097-145f-4bf8-9ed2-20aaba6d7c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.get_axes() # show the axes objects in the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba5a69d-e2f0-4b47-ac5c-b95e306ad462",
   "metadata": {},
   "source": [
    "In the cell below, write a line of code that retrieves the colorbar **Axes** object from the output of `fig.get_axes()`, and assign that to an object called `cax`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569f8fc9-826d-4923-a1f0-cb2747a08341",
   "metadata": {},
   "outputs": [],
   "source": [
    "cax = # fill in the rest!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb61c12-ec83-4174-937e-1acfaa7e814e",
   "metadata": {},
   "source": [
    "Now, run the following cell to update the title and colorbar label. We're changing the title to tell us what sensor the band comes from (EO-1 Hyperion), and we're changing the colorbar label in two ways:\n",
    "\n",
    "1. making it all one line (rather than split over two lines)\n",
    "2. using ([LaTeX](https://matplotlib.org/stable/users/explain/text/usetex.html)) formatting so that the units are displayed as W m<sup>-2</sup> sr<sup>-1</sup> Âµm<sup>-1</sup>, rather than W/m^2/sr/Âµm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f73176-2311-4477-9fa9-172191bc75fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnum = 8 # set the band number\n",
    "ax.set_title(f\"EO-1 Hyperion Band {bnum}\") # set a new title for the figure\n",
    "\n",
    "cax.set_ylabel(\"Measured at-sensor radiance (W m$^{-2}$ sr$^{-1}$ Âµm$^{-1}$)\") # replace the ylabel with a tex-formatted string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chubby-asthma",
   "metadata": {},
   "source": [
    "After running the cell above, you should see the title and labels on the figure change.\n",
    "\n",
    "### 1.4 Displaying an RGB composite\n",
    "\n",
    "To get a bit better overview, we can display an RGB composite image using bands 31 (660.85 nm), 20 (548.92 nm), and 11 (457.34 nm), which correspond to parts of visible red, green, and blue wavelengths, respectively.\n",
    "\n",
    "To check this, we'll also look at one of the ways that we can select values from the There are a number of different ways to select values from `xarray.DataArray` objects (see this [documentation](https://docs.xarray.dev/en/latest/user-guide/indexing.html#quick-overview) page for more information). We've already seen one, `.loc`, which we have used to view information about a single layer or value of a `DataArray`. \n",
    "\n",
    "As we will see below, we can also use `.loc` to select multiple layers/values - here, let's use the thre bands that we've mentioned above (31, 20, and 11), to confirm the wavelength values that I listed above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb59ee4-2d86-48be-9ff4-f42457e5bb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo = [31, 20, 11] # create a list of band coordinates\n",
    "\n",
    "ds.wavelength.loc[combo]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af72768-7277-4182-890e-a5f77bb21800",
   "metadata": {},
   "source": [
    "Next, we can use the `plot_rgb()` function defined at the beginning of the notebook to display an RGB composite of these bands. Before running the cell, make sure to add a line that adds a title to the figure, explaining what bands this is an RGB composite of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-cigarette",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_fig, ax = plt.subplots(1, 1, figsize=(6, 10), subplot_kw=dict(projection=utm_crs))\n",
    "ax = plot_rgb(ax, ds, combo, utm_crs)\n",
    "\n",
    "ax.set_title() # update this to include a title with the band combination!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522d7d78-2c00-41a0-b4c2-3c522bf47be8",
   "metadata": {},
   "source": [
    "Hopefully, this looks recognizable as a (roughly) true-color image of the area. You should also hopefully recognize this as having clear atmospheric effects - why is that? If you're not sure, remember that you can always post questions in the discussion board on Blackboard.\n",
    "\n",
    "To help see the atmospheric effects a little bit more clearly, let's use `ax.set_xlim()` ([documentation](https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.set_xlim.html)) and `ax.set_ylim()` ([documentation](https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.set_ylim.html)) to zoom in on Great Wash - the window above will change after you run this cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8823f724-0c35-4f88-8bfb-285d714eda81",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.set_xlim(227500, 231500) # set the x-axis limits\n",
    "ax.set_ylim(4009500, 4016000) # set the y-axis limits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-tongue",
   "metadata": {},
   "source": [
    "In the figure window above, you should see Great Wash more clearly, along with the surroudning area.\n",
    "\n",
    "### 1.4 Plotting spectral curves\n",
    "We can also see how the value of a single pixel varies by band, or wavelength. `xarray` provides two main ways to access these - we can either use the image index (just like we have seen previously with a **list** or a **DataFrame**), or using the `.sel()` method ([documentation](https://docs.xarray.dev/en/latest/generated/xarray.DataArray.sel.html)). \n",
    "\n",
    "In the first case, we'll see how to do this using the index. The next cell will plot the value of the radiance as a function of wavelength for the pixel in row 1950, column 500 (somewhere in the middle of the lake):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-cathedral",
   "metadata": {},
   "outputs": [],
   "source": [
    "row, col = 1950, 500 # set the row, column indices we want to see\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "ax.plot(ds['wavelength'], ds['radiance'][:, row, col])\n",
    "\n",
    "ax.set_title(f\"radiance at {row}, {col}\")\n",
    "ax.set_xlabel('wavelength (nm)')\n",
    "ax.set_ylabel('radiance (W m$^{-2}$ sr$^{-1}$ Âµm$^{-1}$)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revised-asthma",
   "metadata": {},
   "source": [
    "Notice how the radiance is significantly higher in the visible wavelengths (400-700 nm), dropping off substantially above about 600 or so nm - this indicates high radiance values in blue and green wavelengths, and significantly lower values in red and infrared wavelengths - much like we would expect for liquid water.\n",
    "\n",
    "Now, let's see what real-world coordinates correspond to row 1950, column 500. Here, we use the `.y` and `.x` attributes of the **Dataset**, along with the index values, to print the results to the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdc7802-d8fb-437a-86b1-ae238150d5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Row 1950 has a value of {ds.y[1950].values}\")\n",
    "print(f\"Column 500 has a value of {ds.x[500].values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750230ca-61e5-4f91-a542-76a8c4e8ca47",
   "metadata": {},
   "source": [
    "Row 1950, column 500 corresponds to `x`, `y` coordinates of (229800, 4011300). \n",
    "\n",
    "Rather than selecting the image coordinate, we can also select using the `x`,`y` coordinates for the image using `.sel()` - the following should create the same plot as above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "close-worthy",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = 229800, 4011300\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "spec = ds['radiance'].sel(x=x, y=y, method='nearest')\n",
    "\n",
    "ax.plot(ds['wavelength'], spec)\n",
    "\n",
    "ax.set_title(f\"radiance at {x}, {y}\")\n",
    "ax.set_xlabel('wavelength (nm)')\n",
    "ax.set_ylabel('radiance (W m$^{-2}$ sr$^{-1}$ Âµm$^{-1}$)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changed-corner",
   "metadata": {},
   "source": [
    "## 2 Atmospheric Correction\n",
    "Now that we have seen a few ways to view our data, we can try to correct the radiance values for atmospheric effects. At shorter wavelengths (compared to the thermal infrared) like we have here, we tend to see more atmospheric scattering, increasing significantly towards shorter wavelengths - in particular, this makes the image appear more blue. This is owing to the main ways that electromagnetic radiation scatters off of molecules and particles in the atmosphere, something we'll address in more detail during next week's lectures.\n",
    "\n",
    "### 2.1 Band Histogram\n",
    "For now, we'll look at atmospheric correction using dark object subtraction, something that was introduced (optionally) in the Week 1 practical. This technique is where we take the reflectance of an object (either an optically \"dark\" object, or objects in shadow) and subtract the observed radiance values for that object from the rest of the image.\n",
    "\n",
    "Rather than searching the image for a suitable object, we're going to use a percentile approach - taking the radiance value that is only brighter than 0.5% of the image. First, we will check this by looking at the histogram for Band 8, using `plt.hist()` ([documentation](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.hist.html)).\n",
    "\n",
    "We'll use both `density=True` and `cumulative=True`, along with `histtype='step'`, so that what we see is the cumulative frequency for each set of values, displayed as a \"step\" plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "large-commons",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ds['radiance'].loc[8].values.flatten() # this gives us a vector array that we can pass to plt.hist()\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "_ = ax.hist(data[data > 0], 20, density=True, cumulative=True, histtype='step') # make sure to take only the values > 0,\n",
    "# otherwise we'll end up with a ton of 0 (nodata) values\n",
    "\n",
    "ax.set_ylabel('cumulative frequency')\n",
    "ax.set_xlabel('radiance (W m$^{-2}$ sr$^{-1}$ Âµm$^{-1}$)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "better-compatibility",
   "metadata": {},
   "source": [
    "Note that there are a few values around 0, but most of the values seem to be between 60 and 120 W m<sup>-2</sup> sr<sup>-1</sup> Âµm<sup>-1</sup>. Based on this, a good estimate for the dark object radiance in this band seems to be around 60 W m<sup>-2</sup> sr<sup>-1</sup> Âµm<sup>-1</sup>. \n",
    "\n",
    "### 2.2 Finding the dark object value in each band\n",
    "But, we don't want to have to do this by hand for every single band - instead, we'll use `numpy.percentile()` ([documentation](https://numpy.org/doc/2.1/reference/generated/numpy.percentile.html)) to calculate the value for us (this is, after all, one of the points of doing things programmatically).\n",
    "\n",
    "In this cell, we'll first calculate the values for each band, then plot these values as a function of the band's wavelength:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chicken-nitrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "dark_obj = []\n",
    "for b in ds['radiance']:\n",
    "    # by selecting values where the value > 0, we ignore the nodata values\n",
    "    dark_obj.append(np.percentile(b.values[b.values > 0], 0.5))\n",
    "\n",
    "dark_obj = np.array(dark_obj)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "ax.plot(ds['wavelength'], dark_obj)\n",
    "\n",
    "ax.set_ylabel('radiance (W m$^{-2}$ sr$^{-1}$ Âµm$^{-1}$)')\n",
    "ax.set_xlabel('wavelength (nm)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "later-leadership",
   "metadata": {},
   "source": [
    "Notice how the value drops rapidly once we get through the visible wavelengths - again, this is because we expect to see the amount of atmospheric scattering drop exponentially as wavelength increases. We'll come back to these values again later when we look at individual reflectance curves.\n",
    "\n",
    "## 3 Calculating reflectance\n",
    "\n",
    "### 3.1 Solar radiance\n",
    "Before we calculate reflectance, however, we need to know what the incident radiation is. In the `data` folder is a file called `solar_spectra.csv`, which contains values of extraterrestrial spectral irradiance downloaded from the [National Renewable Energy Laboratory](https://www.nrel.gov/grid/solar-resource/spectra-am1.5.html). These are provided as spectral irradiance in units of W m<sup>-2</sup> nm<sup>-1</sup>, which means that we need to multiply by 1000 (to convert from nm<sup>-1</sup> to Âµm<sup>-1</sup>), and divide by 4&pi; (to get values in W m<sup>-2</sup> sr<sup>-1</sup> Âµm<sup>-1</sup>) in order to compare with our satellite-derived values.\n",
    "\n",
    "We'll also plot the dark object radiance and the radiance for our sample pixel in the lake, in order to see how they compare to the solar irradiance values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collected-david",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/solar_spectra.csv')\n",
    "\n",
    "etr_rad = df.etr * 1000 # convert to \"per nanometer\" values\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "# note: in the line below, we divide by 4pi to get the value per steradian, to match with the units\n",
    "ax.plot(df.wavelength, etr_rad / 4 / np.pi, 'b', label='solar irradiance')\n",
    "\n",
    "ax.plot(ds['wavelength'], dark_obj, 'r', label='dark object radiance')\n",
    "ax.plot(ds['wavelength'], spec, 'k', label='measured radiance')\n",
    "\n",
    "ax.set_xlabel('wavelength (nm)')\n",
    "ax.set_ylabel('spectral radiance (W m$^{-2}$ sr$^{-1}$ nm$^{-1}$)')\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stopped-collapse",
   "metadata": {},
   "source": [
    "### 3.2 Calculating reflectance using COST\n",
    "\n",
    "Now that we have the dark object radiance for each band and the solar irradiance, we can calculate the reflectance &rho;<sub>&lambda;</sub> using the corrected radiance (_L_<sub>&lambda;</sub> - _L_<sub>dark</sub>) and the solar irradiance (_L_<sub>sun</sub>):\n",
    "\n",
    "![the COST equation](img/cost_eqn.png)\n",
    "\n",
    "Where _d_ is the Earth-Sun distance in [Astronomical Units](https://en.wikipedia.org/wiki/Astronomical_unit) and _&theta;_<sub>z</sub> is the solar zenith angle (to get this, we subtract the sun elevation angle found in the metadata, 65.098308, from 90). From the provided MTL.txt file (line 300), the value of the solar elevation angle is 65.098308Â°. Note that we also need to convert the zenith angle from degrees to radians using `np.deg2rad()` ([documentation](https://numpy.org/doc/stable/reference/generated/numpy.deg2rad.html)).\n",
    "\n",
    "For the scene we are using, acquired 22 June 2003, the Earth-Sun distance is 152040710.84 km, or about 1.0163294 AU.\n",
    "\n",
    "The plot below will show the reflectance values for the pixel over the lake that we have used previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-blank",
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_zenith = np.deg2rad(90 - 65.098308) # solar zenith angle converted to radians\n",
    "es_dist = 152040710.84 / 149597870.700 # earth-sun distance converted to astronomical units\n",
    "\n",
    "refl_toa = (spec * es_dist**2 * np.pi) / (etr_rad * np.cos(solar_zenith)**2) # compute the top of atmosphere reflectance\n",
    "refl = ((spec - dark_obj) * es_dist**2 * np.pi) / (etr_rad * np.cos(solar_zenith)**2) # compute reflectance after dark object subtraction\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "ax.plot(ds['wavelength'], refl_toa, label='Top-of-Atmosphere Reflectance')\n",
    "ax.plot(ds['wavelength'], refl, label='Corrected Reflectance')\n",
    "\n",
    "ax.set_xlabel('wavelength (nm)')\n",
    "ax.set_ylabel('spectral reflectance')\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anticipated-creek",
   "metadata": {},
   "source": [
    "Looking at the plot above, can you see where a few different \"atmospheric windows\" are located?\n",
    "\n",
    "Next, we'll define a function, `calculate_reflectance()`, and apply it to each band's radiance values to get the reflectance in each band. Then, we'll add this variable to our dataset by first creating a **DataArray** object ([documentation](https://docs.xarray.dev/en/latest/generated/xarray.DataArray.html#xarray.DataArray))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-financing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_reflectance(radiance, dark, etr, d, theta_z):\n",
    "    return ((radiance - dark) * d**2 * np.pi) / (etr * np.cos(theta_z)**2)\n",
    "\n",
    "reflectances = []\n",
    "for ind, band in enumerate(ds['radiance']):\n",
    "    this_refl = calculate_reflectance(band.values, dark_obj[ind], etr_rad[ind], es_dist, solar_zenith)\n",
    "    this_refl[band.values == 0] = 0 # make sure that values that were 0 stay 0.\n",
    "    this_refl[this_refl < 0] = 0.01 # set negative reflectance to a low value\n",
    "    reflectances.append(this_refl)\n",
    "\n",
    "# add a new variable to the dataset, reflectance, using the values calculated above\n",
    "ds['reflectance'] = xr.DataArray(np.array(reflectances), dims=['band', 'y', 'x'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "employed-thousand",
   "metadata": {},
   "source": [
    "Finally, we'll show the RGB image again, side-by-side with the atmospherically-corrected reflectance values. You should notice that the corrected image appears crisper, in addition to being significantly less blue - again, this is in part due to the increased scattering seen at shorter wavelengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate-hampton",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_fig, axs = plt.subplots(1, 2, figsize=(8, 10), subplot_kw=dict(projection=utm_crs))\n",
    "\n",
    "axs[0] = plot_rgb(axs[0], ds, combo, utm_crs, variable='radiance')\n",
    "axs[1] = plot_rgb(axs[1], ds, combo, utm_crs, variable='reflectance')\n",
    "\n",
    "axs[0].set_title('Raw radiance')\n",
    "axs[1].set_title('Atmospherically-corrected reflectance')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-chorus",
   "metadata": {},
   "source": [
    "Comparing the two images side-by-side, you should hopefully be able to see the difference between the top-of-atmosphere reflectance and the corrected reflectance. What are the main differences that you can see?\n",
    "\n",
    "## 4. Spectral Angle Mapping\n",
    "\n",
    "### 4.1 Using a single end member\n",
    "Next up, we'll see how we can calculate the angle between the spectral vector for our example pixel and water. We'll start by loading our spectral library samples, then calculate the spectral angle &alpha; according to the formula:\n",
    "\n",
    "![spectral angle mapping formula](img/sam_eqn.png)\n",
    "\n",
    "For this, we'll use [Spectral Python](https://www.spectralpython.net/) (SPy), a python module for processing hyperspectral data. In addition to spectral angle mapping, SPy also has a number of algorithms that we have discussed, including minimum noise fraction (MNF) and principal component analysis (PCA), and it also includes tools for querying the ECOSTRESS Spectral Library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocational-savings",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the spectral library values that have been re-sampled to the same wavelengths as the EO-1 image.\n",
    "spectral_library = pd.read_csv('data/spectral_library.csv')\n",
    "\n",
    "water_angles = spy.spectral_angles(ds['reflectance'].values.transpose([1, 2, 0]), \n",
    "                                   spectral_library['water'].values.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0534f614-2519-4179-8763-a7bce16dd709",
   "metadata": {},
   "source": [
    "First, though, let's plot the end members in our spectral library, so we have some idea of what their spectral signatures look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b1e2ec-9202-402b-975e-2b025ac4463c",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_members = list(spectral_library.columns) # get the columns of the dataframe\n",
    "end_members.remove('wavelength') # remove the wavelength column from our list of end members\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "for mem in end_members:\n",
    "    ax.plot(spectral_library.wavelength, spectral_library[mem], label=mem)\n",
    "\n",
    "ax.set_ylabel('reflectance')\n",
    "ax.set_xlabel('wavelength [nm]')\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.) # add a legend\n",
    "\n",
    "fig.tight_layout() # use this to make sure we can see the legend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "postal-purchase",
   "metadata": {},
   "source": [
    "We can now look at the spectral angle for each pixel - we'll focus on the lake so we can get an idea of how well it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-relative",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "ang_im = ax.imshow(water_angles[1800:2000, 450:540], vmin=0.5, vmax=0.8)\n",
    "cax = fig.colorbar(ang_im)\n",
    "\n",
    "cax.set_label('spectral angle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collect-stuff",
   "metadata": {},
   "source": [
    "You should see that the water has a comparatively small angle (dark colors), while the land has a typically larger angle. Overall, it seems to have worked as we might expect, although it does appear somewhat noisy.\n",
    "\n",
    "With one spectral signature like this example, we could choose a threshold angle for binary classification - pixels with an angle less than the given threshold would be classified as water, and pixels with an angle larger than the given threshold would be classified as 'not water'\n",
    "\n",
    "To see why the results for this example might be somewhat noisy, let's look at the reflectance spectra for a few example pixels from the lake:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-sperm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also select a range of pixels using xarray\n",
    "# in this example, we're selecting based on a range of x and y values\n",
    "test_pixels = ds['reflectance'].sel(x=np.linspace(229300, 229600, 10),\n",
    "                                    y=np.linspace(4011800, 4012100, 10), method='nearest')\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(ds['wavelength'], test_pixels.values.reshape(194, -1), '0.5')\n",
    "ax.plot(ds['wavelength'], spectral_library['water'].values, 'k')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "configured-church",
   "metadata": {},
   "source": [
    "In the example above, we can see that there's quite a bit of noise in our reflectance spectra - this is contributing to the noise we can see in the spectral angle results.\n",
    "\n",
    "### 4.2 Multiple end members\n",
    "\n",
    "With additional reference spectra (end members), we can find which end member each pixel is 'closest' to. With `spy.spectral_angles()` ([documentation](https://www.spectralpython.net/class_func_ref.html#spectral-angles)), we can use as many end members as we have data for. In the next example will do this for all of our reference spectra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manual-genetics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spectral_angles expects the data to have a shape (rows, columns, bands), while our data are (bands, rows, columns)\n",
    "# we also need to transpose our spectral library data so that the rows correspond to each end member\n",
    "all_angles = spy.spectral_angles(ds['reflectance'].values.transpose([1, 2, 0]), \n",
    "                                 spectral_library[end_members].values.transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dynamic-heart",
   "metadata": {},
   "source": [
    "Using `np.argmin()` ([documentation](https://numpy.org/doc/stable/reference/generated/numpy.argmin.html)), we can then display an image where the value of each pixel corresponds to the end member with the smallest angle for each pixel - in other words, the best match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-quarterly",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "# this will tell us which end member has the smallest spectral angle for each pixel\n",
    "best_match = np.argmin(all_angles, axis=2)\n",
    "\n",
    "# this will set the nodata pixels to be masked so that we don't see them in the plot\n",
    "best_match = np.ma.masked_array(best_match, mask=ds['reflectance'].loc[8] == 0)\n",
    "\n",
    "ax.imshow(best_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "difficult-grammar",
   "metadata": {},
   "source": [
    "Here, we can see that the Lake has a fairly uniform value of 0, indicating that we've done a good job classifying the water. We can also see that in the northern part of the image, we have a number of areas where we've successfully picked out the stands of ponderosa pines (value of 1). While most of the image has been classified as sandstone, we know from the [geologic maps](http://data.azgs.az.gov/geologic-map-of-arizona/) of the area that this isn't completely correct - we should see areas of basalts and other types of bedrock.\n",
    "\n",
    "To get a better classification of the image, we would want to be sure to pick out additional end members, and possibly even include multiple samples - remember that small differences in grain size or chemical composition can have a large impact on the spectral signature. Remember that you can add additional end members from the [USGS Spectral Library](https://www.usgs.gov/labs/spectroscopy-lab/usgs-spectral-library) by downloading the data files and using `data/combine_spectral_library.py` to add the new end members to `data/spectral_library.csv`.\n",
    "\n",
    "While these results aren't bad for an initial attempt, the image is still relatively noisy. To help reduce the impact of the noise in the data, we might also consider using the minimum noise fraction or a similar data reduction technique.\n",
    "\n",
    "### 4.3 Exporting the results\n",
    "\n",
    "As a last step, we'll export this classified image to a raster file using `rasterio`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-bandwidth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio as rio\n",
    "\n",
    "with rio.open('EO1H0380352003173110PF_RGB.tif', 'r') as src:\n",
    "    profile = src.profile\n",
    "    profile.update({'dtype': np.uint8, 'count': 1, 'nodata': 255})\n",
    "    with rio.open('sam_classification.tif', 'w', **profile) as dst:\n",
    "        dst.write(best_match.astype(np.uint8), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peripheral-corporation",
   "metadata": {},
   "source": [
    "You should be able to load the classified raster in a GIS software such as ArcGIS Pro or QGIS, and calculate the area and percent coverage of each end member in the image. Alternatively, you could also do this by editing the notebook. :)\n",
    "\n",
    "That will wrap us up for this week's practical - as mentioned, there are a number of additional algorithms available from `spectral` - for a full list, check out the full [API documentation](https://www.spectralpython.net/class_func_ref.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
